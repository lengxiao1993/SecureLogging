from base64 import b64encode, b64decode
from binascii import hexlify
from struct import pack, unpack

from json import loads
from bisect import bisect_left
# import bsddb

from future.moves import dbm

from traceback import print_stack, print_exc
from hashlib import sha256
from os.path import join

from petlib.ec import EcPt

from twisted.internet import protocol
from twisted.protocols.basic import LineReceiver
from twisted.python import log

import rscoin
from datetime import datetime 
import pymongo
from pymongo import MongoClient
from py._path.svnwc import LogEntry
import pickle


class RSCLogEntry:
    """Represents a log entry that will be stored in the logging database"""
    def __init__(self, data = None, action = None, sig = None, lampClock = None):
        """ Make a key given a public or private key in bytes """
        """ sig is the signature from the current mintette"""
        self.ser = None
        if action == None:
            self.processedTx = None
            self.parentTx = None
            self.lampClock = None
            self.action = None
        
            """
            inputAddrKeys are the public keys that correspond to output addr
            in the input transactions
            """
            self.inputAddrKeys = None  
            self.inputSigs = None
            self.hashhead = None
            
            return 
        
        self.utcTimestamp = datetime.utcnow() 
        #notice unlike mainTx, otherTx is unparsed data bytes
        
        """
        mainTx type: Tx
        otherTx type: [Tx.serialize]
        keys type: 
        sigs : 
        """
        
        
        if action == "Commit_Success":
            
            
            (H, mainTx, otherTx, keys, sigs, 
                auth_keys, auth_sigs, hashheads, seqStrs, items) = data
            
            self.processedTx = mainTx
            self.parentTx = otherTx
            self.lampClock = lampClock
            self.action = action
            
            """
            InputAddrKeys are the public keys that correspond to output addr
            in the input transactions
            """
            
            self.inputAddrKeys = keys  
            self.inputSigs = sigs
            
            
            """
            authKeys are the public keys of mintettes who own the input txs 
            authSigs are the signatures generated by mintettes who own input txs
            """
            self.authKeys = auth_keys  
            self.authSigs = auth_sigs
            
            
            '''head of hash chain'''
            self.hashheads = hashheads
            self.seqStrs = seqStrs
            
        if action == "Query_Success":
            (mainTx, otherTx, keys, sigs) = data
            
            self.processedTx = mainTx
            self.parentTx = otherTx
            self.lampClock = lampClock
            self.action = action
            
            """
            inputAddrKeys are the public keys that correspond to output addr
            in the input transactions
            """
            self.inputAddrKeys = keys  
            self.inputSigs = sigs
            
            
    def serialize(self):
        if self.ser is not None:
            return self.ser

        ser = pack("H", len(self.parentTx))
        
        ser += pack("HH", len(self.inputAddrKeys), len(self.inputSigs))
        
        ser += self.processedTx.serialize()
        
        for tx in self.parentTx:
            ser += pack("H", len(tx))
            ser += tx
            
        for addrKey in self.inputAddrKeys:
            ser += pack("H", len(addrKey))
            ser += addrKey
        
        for sig in self.inputSigs:
            ser += sig
        

        self.ser = ser

        return ser
    
    
    
            
            
            
def encode_log_entry_to_json(logEntry):
    """ Transform the log entry to jason format dict to store into MongoDB """
     
    
    if logEntry.action == "Query_Success" or "Commit_Success":
        # Common fileds for query and commit log entry
        json_dict= {"date": logEntry.utcTimestamp,
                      "action": logEntry.action,
                      "lampClock": logEntry.lampClock,
                      "processedTxId": b64encode(logEntry.processedTx.id()),
                      }
        
        inputAddrKeys = [ b64encode(key) for key in logEntry.inputAddrKeys ]
        json_dict.update({"inputAddrKeys" : inputAddrKeys})       
        
        inputSigs = [ b64encode(sig) for sig in logEntry.inputSigs]
        json_dict.update({"inputSigs" : inputSigs})
        
        
        inputAddrIds = [{"tx_id": b64encode(addrId.tx_id),
                        "pos" : addrId.pos
                        } for addrId in logEntry.processedTx.inTx]
          
        json_dict.update({"inputAddrIds": inputAddrIds})
        
        outputAddrIds = [{"key_id" : b64encode(outAddrId.key_id),
                         "value": outAddrId.value
                         } for outAddrId in logEntry.processedTx.outTx  ]
        
        json_dict.update({"outputAddrIds": outputAddrIds})
        
        inputTxs = [b64encode(tx) for tx in logEntry.parentTx]
        
        json_dict.update({"inputTxs": inputTxs})
        
        json_dict.update({"processedTx_R": b64encode(logEntry.processedTx.R)})
    
    if logEntry.action == "Commit_Success":
        authKeys = [ b64encode(key) for key in logEntry.authKeys ]
        json_dict.update({"authKeys" : authKeys})       
        
        authSigs = [ b64encode(sig) for sig in logEntry.authSigs ]
        json_dict.update({"authSigs" : authSigs})
        
        hashheads = [ b64encode(head) for head in logEntry.hashheads ]
        json_dict.update({"hashheads" : hashheads})
    
    
    return json_dict


def decode_json_to_log_entry(jason_dict):
    
    
    logEntry = RSCLogEntry()
    
    logEntry.action = jason_dict["action"]
    
    if(logEntry.action == "Query_Success" or "Commit_Success"):
    
        logEntry.utcTimestamp = jason_dict["date"]
        
        logEntry.lampClock = jason_dict["lampClock"]
        
        inputAddrIds = [
                        rscoin.InputTx(b64decode(addrId["tx_id"]),int(addrId["pos"])) 
                        
                        for addrId in jason_dict["inputAddrIds"]]
        '''                    
        outputAddrIds = [{"key_id" : b64encode(outAddrId.key_id),
                         "value": outAddrId.value
                         } for outAddrId in logEntry.processedTx.outTx  ]
        
        jason_dict.update({"outputAddrIds": outputAddrIds})
        '''
        outputAddrIds = [
                         rscoin.OutputTx(b64decode(outAddrId["key_id"]), int(outAddrId["value"]))
                         for outAddrId in jason_dict["outputAddrIds"]
                         ]
        
        processedTx = rscoin.Tx(inputAddrIds, outputAddrIds, 
                                b64decode(jason_dict["processedTx_R"]))
        
        logEntry.processedTx = processedTx 
        
        
        inputAddrKeys = [ b64decode(key) for key in jason_dict["inputAddrKeys"] ]
        logEntry.inputAddrKeys = inputAddrKeys      
        
        inputSigs = [ b64decode(sig) for sig in jason_dict["inputSigs"]]
        logEntry.inputSigs = inputSigs
        
        
        
        inputTxs = [b64decode(tx) for tx in jason_dict["inputTxs"]]
        logEntry.parentTx = inputTxs
        
        
    
    if(logEntry.action == "Commit_Success"):
        authKeys = [ b64decode(key) for key in jason_dict["authKeys"] ]
        logEntry.authKeys = authKeys      
        
        authSigs = [ b64decode(sig) for sig in jason_dict["authSigs"]  ]
        logEntry.authSigs = authSigs
        
        hashheads = [ b64decode(head) for head in jason_dict["hashheads"] ]
        logEntry.hashheads = hashheads
         
    
    return logEntry

class RSCLogger:
    def __init__(self, ip = "localhost", port=27017):
        self.client = MongoClient(ip,port)
        self.db = self.client.RSC_Log_Database
        self.collection = self.db.log_collection
        self.db.collection.create_index([("lampClock", pymongo.ASCENDING)])
        
        
    def write_log(self, logEntry): 
        json_entry = encode_log_entry_to_json(logEntry)             
        self.collection.insert(json_entry)
        
    def query_log_by_time(self, timestamp):
        json_entry = self.collection.find_one({"date":timestamp})
        
        return json_entry
    def query_log_by_processedTxId(self, processedTxId):
        json_entry = self.collection.find_one({"processedTxId":
                                                 b64encode(processedTxId)})
        
        return json_entry
    def query_log_by_sequenceNum(self, seq ):
        json_entry = self.collection.find_one({"lampClock": seq})
        return json_entry

    def verify_log(self, seq, hashhead):
        """
        Given the sequence number and hash head 
        Verify log items within sequence number area: 1-seq 
        """
        logEntries = self.collection.find({"lampClock":{"$lte":seq}}) \
                       .sort("lampClock",pymongo.ASCENDING)
        
        for json_string in logEntries:
            logEntry = decode_json_to_log_entry(json_string)
            if logEntry.lampClock == 1:
                hash_head = sha256(logEntry.serialize()+"").digest()
            else:
                hash_head = sha256(logEntry.serialize()+hash_head).digest()
        
        return hash_head == hashhead
        
    def query_hashhead(self, transactionId, pub, seq):    
        """
        factory.key.pub.export(EcPt.POINT_CONVERSION_UNCOMPRESSED)
        return the unique hash head produced for log[seq] by auditied mintette    
        """
        json_entry = self.collection.find_one({
                                               "processedTxId":b64encode(transactionId),
                                               "action": "Commit_Success",
                                               "lampClock": seq
                                               })
        
        if(json_entry == None):
            return None
        
        logEntry = decode_json_to_log_entry(json_entry)
        index = logEntry.authKeys.index(pub)
        hashhead = logEntry.hashheads[index]
        return hashhead
 
